{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c6e80a-c7dd-4fff-a91d-bfa39a98bad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringLookup\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907e8df8-236a-4d8a-b093-f738450801cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_file_path = \"./words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31191671-6ffb-4efe-80f2-6c895af662e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96456\n",
      "['a01-000u-00-00 ok 154 408 768 27 51 AT A\\n', 'a01-000u-00-01 ok 154 507 766 213 48 NN MOVE\\n', 'a01-000u-00-02 ok 154 796 764 70 50 TO to\\n', 'a01-000u-00-03 ok 154 919 757 166 78 VB stop\\n', 'a01-000u-00-04 ok 154 1185 754 126 61 NPT Mr.\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(words_file_path, 'r') as file:\n",
    "    words = file.readlines()\n",
    "\n",
    "words_list = []\n",
    "\n",
    "for line in words:\n",
    "  if line[0]==\"#\":\n",
    "    continue\n",
    "  if line.split(\" \")[1] != \"err\":  # we do not need to deal with errored entries.\n",
    "    words_list.append(line)\n",
    "\n",
    "print(len(words_list))\n",
    "print(words_list[:5])\n",
    "\n",
    "np.random.shuffle(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffae2104-5c3f-4a22-a629-b26088346d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data samples: 96456\n",
      "Total training samples: 86810\n",
      "Total validation samples: 4823\n",
      "Total test samples: 4823\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(0.9 * len(words_list))\n",
    "train_samples = words_list[:split_idx]\n",
    "test_samples = words_list[split_idx:]\n",
    "\n",
    "val_split_idx = int(0.5 * len(test_samples))\n",
    "validation_samples = test_samples[:val_split_idx]\n",
    "test_samples = test_samples[val_split_idx:]\n",
    "\n",
    "assert len(words_list) == len(train_samples) + len(validation_samples) + len(test_samples)\n",
    "\n",
    "print(f\"Total data samples: {len(words_list)}\")\n",
    "print(f\"Total training samples: {len(train_samples)}\")\n",
    "print(f\"Total validation samples: {len(validation_samples)}\")\n",
    "print(f\"Total test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc8ac12-0fc3-4b76-aa10-a073bf948c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path =\"./words\"\n",
    "\n",
    "def get_image_paths_and_labels(samples):\n",
    "  paths = []\n",
    "  corrected_samples = []\n",
    "  for(i,file_line) in enumerate(samples):\n",
    "    line_split = file_line.strip()\n",
    "    line_split = line_split.split(\" \")\n",
    "    #each file_line is as \"a01-000u-00-03 ok 154 919 757 166 78 VB stop\"\n",
    "    # part1/part1-part2/part1-part2-part3.png\n",
    "\n",
    "    image_name = line_split[0]\n",
    "    partI = image_name.split(\"-\")[0]\n",
    "    partII = image_name.split(\"-\")[1]\n",
    "    img_path = os.path.join(\n",
    "        base_image_path, partI , partI + \"-\" + partII, image_name + \".png\"\n",
    "    )\n",
    "\n",
    "\n",
    "    if os.path.getsize(img_path):\n",
    "      paths.append(img_path)\n",
    "      corrected_samples.append(file_line.split(\"\\n\")[0])\n",
    "\n",
    "  return paths, corrected_samples\n",
    "\n",
    "\n",
    "train_img_paths, train_labels = get_image_paths_and_labels(train_samples)\n",
    "validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\n",
    "test_img_paths, test_labels = get_image_paths_and_labels(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704fee7e-ae3a-4a6e-9b9c-e09a6c293820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./words\\\\e04\\\\e04-030\\\\e04-030-04-08.png', './words\\\\k02\\\\k02-102\\\\k02-102-05-03.png', './words\\\\a01\\\\a01-082u\\\\a01-082u-01-04.png', './words\\\\m01\\\\m01-000\\\\m01-000-07-00.png', './words\\\\g01\\\\g01-031\\\\g01-031-07-06.png', './words\\\\f07\\\\f07-081b\\\\f07-081b-01-06.png', './words\\\\n03\\\\n03-082\\\\n03-082-04-03.png', './words\\\\g06\\\\g06-018c\\\\g06-018c-04-05.png', './words\\\\g06\\\\g06-011j\\\\g06-011j-06-06.png', './words\\\\f04\\\\f04-024\\\\f04-024-01-06.png']\n",
      "['e04-030-04-08 ok 170 1489 1499 120 39 JJ sure', 'k02-102-05-03 ok 182 836 1623 69 52 PP3A he', 'a01-082u-01-04 ok 172 1582 1043 234 88 IN during', 'm01-000-07-00 ok 196 339 1998 75 107 INO of', 'g01-031-07-06 ok 152 1912 2038 167 59 NN booty', 'f07-081b-01-06 ok 168 1366 924 350 88 NN gastronomy', 'n03-082-04-03 ok 165 992 1414 118 135 NN boy', 'g06-018c-04-05 ok 182 1298 1438 96 58 ATI The', 'g06-011j-06-06 ok 182 1222 1785 146 95 CC and', 'f04-024-01-06 ok 183 1104 981 60 70 IN in']\n"
     ]
    }
   ],
   "source": [
    "print(train_img_paths[0:10])\n",
    "print(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13235219-e283-4c97-b59e-75675cfef918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Length: 21\n",
      "Vocab size: 78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sure',\n",
       " 'he',\n",
       " 'during',\n",
       " 'of',\n",
       " 'booty',\n",
       " 'gastronomy',\n",
       " 'boy',\n",
       " 'The',\n",
       " 'and',\n",
       " 'in']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the maximum length and the size of the vocabulary in the training data.\n",
    "train_labels_cleaned = []\n",
    "characters = set()\n",
    "max_len = 0\n",
    "\n",
    "for label in train_labels:\n",
    "  label = label.split(\" \")[-1].strip()\n",
    "  for char in label:\n",
    "    characters.add(char)\n",
    "\n",
    "  max_len = max(max_len, len(label))\n",
    "  train_labels_cleaned.append(label)\n",
    "\n",
    "print(\"Maximum Length:\",max_len)\n",
    "print(\"Vocab size:\",len(characters))\n",
    "\n",
    "#checking\n",
    "\n",
    "train_labels_cleaned[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb37f6b-d652-43b2-9ee5-f11877b75cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(labels):\n",
    "  cleaned_labels = []\n",
    "  for label in labels:\n",
    "    label = label.split(\" \")[-1].strip()\n",
    "    cleaned_labels.append(label)\n",
    "\n",
    "  return cleaned_labels\n",
    "\n",
    "validation_labels_cleaned= clean_labels(validation_labels)\n",
    "test_labels_cleaned = clean_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cf84f6-339c-4963-84f2-746ad6d9635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T', 'F', 'c', '\"', 'd', 'B', '!', 'h', 'A', 'J', 'j', 'K', 'l', ',', 'H', 'v', '1', 'W', 'P', 'N', 'U', 'I', '9', 'x', 'f', 's', 'z', 'm', 'p', 'C', 'E', 'r', '#', 'G', '-', 'Q', 'M', 'g', 'D', 'y', '5', \"'\", '?', 'S', 'V', '&', 'Z', 'i', 'O', 't', '8', 'w', '.', '2', 'n', '6', 'e', '3', 'u', 'X', 'L', 'k', '7', 'a', ')', 'q', 'b', '/', '(', 'o', '+', ':', ';', '0', '*', 'R', 'Y', '4'}\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "print(characters)\n",
    "print(len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420e480d-4aee-4dad-b606-978e45ab61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#TensorFlow will automatically decide the optimal values for characters.\n",
    "\n",
    "#mapping character to integer\n",
    "char_to_num = StringLookup(vocabulary = list(characters), mask_token=None)\n",
    "\n",
    "#mapping integers back to original characters.\n",
    "num_to_char = StringLookup(vocabulary = char_to_num.get_vocabulary(), mask_token=None, invert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7af5a90b-e448-481e-8f2a-e3b03d6c176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "tf.Tensor([9], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(char_to_num(tf.constant([\"A\"])))\n",
    "#here A got value 76\n",
    "# the values nott in the characters  list gets value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd500313-8363-4b32-9b0f-6c7f6fdb42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "  w,h = img_size\n",
    "  image = tf.image.resize(image, size=(h,w),preserve_aspect_ratio=True)  # size paraeter takes height first and then width\n",
    "  #The resulting image might not be exactly (h,w) pixels but will fit within these dimensions without any distortion.\n",
    "  # if any pixel left we will use padding\n",
    "\n",
    "  #checking the padding height and width\n",
    "  pad_height = h-tf.shape(image)[0]\n",
    "  pad_width = w-tf.shape(image)[1]\n",
    "\n",
    "  #Only necessary if you want to do some amount of padding on both sides.\n",
    "  if pad_height % 2 !=0:\n",
    "    height=pad_height//2\n",
    "    pad_height_top = height +1\n",
    "    pad_height_bottom = height\n",
    "  else:\n",
    "    pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "  if pad_width %2 != 0:\n",
    "    width = pad_width //2\n",
    "    pad_width_left = width +1\n",
    "    pad_width_right = width\n",
    "  else:\n",
    "    pad_width_left = pad_width_right = pad_width //2\n",
    "\n",
    "  image = tf.pad(\n",
    "      image,\n",
    "      paddings = [\n",
    "          [pad_height_top, pad_height_bottom],\n",
    "          [pad_width_left, pad_width_right],\n",
    "          [0,0],\n",
    "      ],\n",
    "\n",
    "  )\n",
    "  image = tf.transpose(image, perm=[1,0,2])\n",
    "  image = tf.image.flip_left_right(image)\n",
    "  # because tf.resize uses (h,w) way\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f022843-c8a3-4fe0-9558-5ff601cb6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32\n",
    "\n",
    "def preprocessing_image(image_path, img_size=(image_width, image_height)):\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_png(image,channels=1) # decode the png_encoded images into tensor , channel 1 for gray scale\n",
    "  image = distortion_free_resize(image,img_size)\n",
    "  image = tf.cast(image, tf.float32)/255.0  # data type conversion in tensor\n",
    "  return image\n",
    "\n",
    "def vectorize_label(label):\n",
    "  label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "  length = tf.shape(label)[0]\n",
    "  pad_amount = max_len-length\n",
    "  label = tf.pad(label, paddings=[[0,pad_amount]], constant_values = padding_token)\n",
    "  return label\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "  image = preprocessing_image(image_path)\n",
    "  label = vectorize_label(label)\n",
    "  return {\"image\":image, \"label\":label}\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(process_images_labels, num_parallel_calls=AUTOTUNE)\n",
    "  return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a55b28-4361-4639-b417-1432dee9e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_dataset(train_img_paths, train_labels_cleaned)\n",
    "validation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)\n",
    "test_ds = prepare_dataset(test_img_paths, test_labels_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9ef8b-f19f-4a9f-b6bd-4befc009b617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
